{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is associated with the manuscript \"Missing data imputation via Gaussian Processes: Indo-Aryan sound change,\" Department of Comparative Linguistics, University of Zurich, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from numpy import log,exp,mean\n",
    "from functools import reduce\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import theano\n",
    "theano.config.gcc.cxxflags = \"-fbracket-depth=1000\"\n",
    "#THEANO_FLAGS = \"-fbracket-depth=1000\"\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and alignment indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "for l in open('cdial_stripped.csv','r'):\n",
    "    text.append(l.strip().split('\\t'))\n",
    "\n",
    "\n",
    "for i in range(len(text)):\n",
    "    for j in range(1,3):\n",
    "        text[i][j] = text[i][j].split()\n",
    "\n",
    "\n",
    "\n",
    "alignments = []\n",
    "for l in open('alignments.txt','r'):\n",
    "    alignments.append([int (i) for i in l.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function extracts sound changes from aligned sequences, along with associated variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = 2\n",
    "D = ng*2\n",
    "def generate_ngrams(ng):\n",
    "    change_counts = defaultdict(int)\n",
    "    lang_changes = defaultdict()\n",
    "    for i in range(len(text)):\n",
    "        lang = text[i][0]\n",
    "        if lang not in lang_changes.keys():\n",
    "            lang_changes[lang] = defaultdict()\n",
    "        x,y=text[i][2],text[i][1]\n",
    "        A = alignments[i]\n",
    "        for j in range(0,len(A)-ng):\n",
    "            before = []\n",
    "            after = []\n",
    "            for k in range(ng):\n",
    "                before.append(tuple(x[j+k:j+k+1]))\n",
    "                after.append(tuple(y[A[j+k]:A[j+k+1]]))\n",
    "            edit = tuple([tuple(before),tuple(after)])\n",
    "            change_counts[edit]+=1\n",
    "            if edit[0] not in lang_changes[lang].keys():\n",
    "                lang_changes[lang][edit[0]] = defaultdict(int)\n",
    "            lang_changes[lang][edit[0]][edit[1]]+=1\n",
    "\n",
    "    all_reflex = defaultdict(list)\n",
    "    for k in change_counts.keys():\n",
    "        if change_counts[k] > 10:\n",
    "            all_reflex[k[0]].append(k[1])\n",
    "            \n",
    "    reflex = defaultdict(list)\n",
    "    for k in all_reflex.keys():\n",
    "        if len(all_reflex[k]) > 1:\n",
    "            reflex[k] = all_reflex[k]\n",
    "            \n",
    "    reflex_list = list(reflex.keys())\n",
    "    change_list = [(k,v) for k in reflex_list for v in reflex[k]]\n",
    "    seg_list = [sorted(set([change[i][j] for change in change_list])) for i in range(2) for j in range(ng)]\n",
    "    seg_len = [len(s) for s in seg_list]\n",
    "    return(reflex,reflex_list,change_list,lang_changes,seg_list,seg_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function generates the pairwise segment dissimilarity matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dissimilarity():\n",
    "    feat_mat = {}\n",
    "    for line in open('feat_matrix.csv','r'):\n",
    "        l = line.split('\\t')\n",
    "        feat_mat[l[0]]=tuple(l[1:])\n",
    "\n",
    "    dissimilarity = {}\n",
    "    dissimilarity[((),())] = 1\n",
    "    for k in feat_mat.keys():\n",
    "        dissimilarity[(('#',),(k,))] = 6\n",
    "        dissimilarity[((k,),('#',))] = 6\n",
    "        dissimilarity[(('#',),('#',))] = 0\n",
    "        for l in feat_mat.keys():\n",
    "            dissim = 0\n",
    "            if feat_mat[k][0]!=feat_mat[l][0]:\n",
    "                dissim += 2\n",
    "            if feat_mat[k][1]!=feat_mat[l][1]:\n",
    "                dissim += 1\n",
    "            if feat_mat[k][2]!=feat_mat[l][2]:\n",
    "                dissim += 1\n",
    "            if feat_mat[k][3]!=feat_mat[l][3]:\n",
    "                dissim += 1\n",
    "            if feat_mat[k][4]!=feat_mat[l][4]:\n",
    "                dissim += 1\n",
    "            dissimilarity[((k,),(l,))] = dissim\n",
    "    return(dissimilarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function generates the pairwise element dissimilarity matrix for each \"dimension\" of a given pair of changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matrix():\n",
    "    Rho = [np.zeros([len(s),len(s)]) for s in seg_list]\n",
    "    for i in range(ng):\n",
    "        for j in range(seg_len[i]):\n",
    "            for k in range(j+1,seg_len[i]):\n",
    "                d = dissimilarity[(seg_list[i][j],seg_list[i][k])]\n",
    "                Rho[i][j,k] = d\n",
    "                Rho[i][k,j] = d            \n",
    "            \n",
    "    for i in range(ng,len(seg_list)):\n",
    "        for j in range(seg_len[i]):\n",
    "            for k in range(j+1,seg_len[i]):\n",
    "                if len(seg_list[i][j]) > 0 and len(seg_list[i][k]) > 0:\n",
    "                    if len(seg_list[i][j]) > 1 and len(seg_list[i][k]) == 1:\n",
    "                        d = np.mean([dissimilarity[((r,),seg_list[i][k])] for r in seg_list[i][j]])\n",
    "                    if len(seg_list[i][j]) == 1 and len(seg_list[i][k]) > 1:\n",
    "                        d = np.mean([dissimilarity[(seg_list[i][j],(s,))] for s in seg_list[i][k]])\n",
    "                    if len(seg_list[i][j]) > 1 and len(seg_list[i][k]) > 1:\n",
    "                        d = np.mean([dissimilarity[((r,),(s,))] for r in seg_list[i][j] for s in seg_list[i][k]])\n",
    "                    if len(seg_list[i][j]) == 1 and len(seg_list[i][k]) == 1:\n",
    "                        d = dissimilarity[(seg_list[i][j],seg_list[i][k])]\n",
    "                else:\n",
    "                    d = 3\n",
    "                Rho[i][j,k] = d\n",
    "                Rho[i][k,j] = d\n",
    "    return(Rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function generates a training and held-out data set for a given language, along with associated variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch(lang):\n",
    "    reflex_list_lang = [k for k in reflex_list if k in lang_changes[lang].keys()]\n",
    "    change_list_lang = [(k,v) for k in reflex_list for v in reflex[k] if k in lang_changes[lang].keys()]\n",
    "    X = len([k for k in reflex_list_lang])\n",
    "    R = [len(reflex[k]) for k in reflex_list_lang] #index and length of each sound change distribution\n",
    "    M = sum([R[i] for i in range(X)])\n",
    "\n",
    "    C = min(100,int(X/3))\n",
    "    partition = [[0,R[0]]]+[[reduce(lambda x,y:x+y,R[:i]),reduce(lambda x,y:x+y,R[:i+1])] for i in range(1,len(R))]\n",
    "    sound_binaries = [np.zeros([M,s]) for s in seg_len]\n",
    "\n",
    "    for s in range(M):\n",
    "        for i in range(2):\n",
    "            for j in range(ng):\n",
    "                sound_binaries[i*ng+j][s,seg_list[i*ng+j].index(change_list_lang[s][i][j])] = 1\n",
    "    \n",
    "    hold_out = sorted(random.sample(range(X),C))\n",
    "    leave_in = sorted(random.sample([x for x in range(X) if x not in hold_out],C))\n",
    "    \n",
    "    #ranges of left in/held out changes\n",
    "    range_leave_in = [partition[i] for i in leave_in]\n",
    "    range_hold_out = [partition[i] for i in hold_out]\n",
    "\n",
    "    #indices\n",
    "    ind_leave_in = []\n",
    "    for p in range_leave_in:\n",
    "        for i in range(p[0],p[1]):\n",
    "            ind_leave_in.append(i)\n",
    "        \n",
    "    ind_hold_out = []\n",
    "    for p in range_hold_out:\n",
    "        for i in range(p[0],p[1]):\n",
    "            ind_hold_out.append(i)        \n",
    "        \n",
    "    R_leave_in = [R[i] for i in leave_in]\n",
    "    R_hold_out = [R[i] for i in hold_out]\n",
    "\n",
    "    N_leave_in = sum(R_leave_in)\n",
    "    N_hold_out = sum(R_hold_out)\n",
    "    \n",
    "    #absolute partitions, for softmax\n",
    "    part_leave_in = [[0,R_leave_in[0]]]+[[reduce(lambda x,y:x+y,R_leave_in[:i]),reduce(lambda x,y:x+y,R_leave_in[:i+1])] for i in range(1,len(R_leave_in))]\n",
    "    part_hold_out = [[0,R_hold_out[0]]]+[[reduce(lambda x,y:x+y,R_hold_out[:i]),reduce(lambda x,y:x+y,R_hold_out[:i+1])] for i in range(1,len(R_hold_out))]\n",
    "    \n",
    "    sound_binaries_leave_in = [sound_binaries[i][ind_leave_in,:] for i in range(ng*2)]\n",
    "    \n",
    "    change_list_leave_in = [(reflex_list_lang[i],v) for i in leave_in for v in reflex[reflex_list_lang[i]]]\n",
    "    change_list_hold_out = [(reflex_list_lang[i],v) for i in hold_out for v in reflex[reflex_list_lang[i]]]\n",
    "    S = len(change_list_leave_in)\n",
    "    T = len(change_list_hold_out)\n",
    "    \n",
    "    sound_count = np.zeros(S)\n",
    "    for j,c in enumerate(change_list_leave_in):\n",
    "        sound_count[j] = lang_changes[lang][c[0]][c[1]]\n",
    "        \n",
    "    sound_count_held_out = np.zeros(T)\n",
    "    for j,c in enumerate(change_list_hold_out):\n",
    "        sound_count_held_out[j] = lang_changes[lang][c[0]][c[1]]\n",
    "        \n",
    "    Sigma = np.array([np.dot(np.dot(sound_binaries_leave_in[i],Rho[i]),sound_binaries_leave_in[i].T) for i in range(ng*2)])\n",
    "    \n",
    "    sound_binaries_full = [sound_binaries[i][ind_hold_out+ind_leave_in,:] for i in range(ng*2)]\n",
    "    Sigma_full = np.array([np.dot(np.dot(sound_binaries_full[i],Rho[i]),sound_binaries_full[i].T) for i in range(ng*2)])\n",
    "    \n",
    "    return(sound_count,sound_count_held_out,Sigma,Sigma_full,N_leave_in,N_hold_out,part_leave_in,part_hold_out,R_leave_in,R_hold_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate the data set, the dissimilarity matrix, and the dimension-level dissimilarity matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflex,reflex_list,change_list,lang_changes,seg_list,seg_len = generate_ngrams(ng)\n",
    "dissimilarity = generate_dissimilarity()\n",
    "Rho = generate_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The languages we are interesting in are not commented out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = [#'ashk1246',\n",
    " 'assa1263',\n",
    "# 'awad1243',\n",
    "# 'bagh1251',\n",
    "# 'balk1252',\n",
    " 'beng1280',\n",
    "# 'bhad1241',\n",
    "# 'bhat1263',\n",
    "# 'bhoj1244',\n",
    "# 'braj1242',\n",
    "# 'brok1247',\n",
    "# 'carp1235',\n",
    "# 'cham1307',\n",
    "# 'chil1275',\n",
    "# 'chur1258',\n",
    "# 'dame1241',\n",
    "# 'dhiv1236',\n",
    "# 'dogr1250',\n",
    "# 'doma1258',\n",
    "# 'doma1260',\n",
    "# 'garh1243',\n",
    "# 'gawa1247',\n",
    "# 'gran1245',\n",
    " 'guja1252',\n",
    "# 'halb1244',\n",
    " 'hind1269',\n",
    "# 'indu1241',\n",
    "# 'jaun1243',\n",
    "# 'kach1277',\n",
    "# 'kala1372',\n",
    "# 'kala1373',\n",
    "# 'kalo1256',\n",
    "# 'kang1280',\n",
    " 'kash1277',\n",
    "# 'kati1270',\n",
    "# 'khet1238',\n",
    "# 'khow1242',\n",
    "# 'kohi1248',\n",
    " 'konk1267',\n",
    "# 'kull1236',\n",
    "# 'kuma1273',\n",
    "# 'loma1235',\n",
    "# 'maga1260',\n",
    "# 'maha1287',\n",
    "# 'maha1305',\n",
    " 'mait1250',\n",
    "# 'malv1243',\n",
    "# 'mand1409',\n",
    " 'mara1378',\n",
    "# 'marw1260',\n",
    " 'nepa1254',\n",
    "# 'nort2665',\n",
    "# 'nort2666',\n",
    " 'oriy1255',\n",
    "# 'paha1251',\n",
    "# 'pali1273',\n",
    "# 'pang1282',\n",
    " 'panj1256',\n",
    "# 'phal1254',\n",
    "# 'pras1239',\n",
    "# 'savi1242',\n",
    "# 'sera1259',\n",
    "# 'shin1264',\n",
    "# 'shum1235',\n",
    " 'sind1272',\n",
    " 'sinh1246',\n",
    "# 'sint1235',\n",
    "# 'sirm1239',\n",
    "# 'sout2671',\n",
    "# 'sout2672',\n",
    "# 'tira1253',\n",
    "# 'torw1241',\n",
    "# 'treg1243',\n",
    "# 'vlax1238',\n",
    "# 'waig1243',\n",
    "# 'wels1246',\n",
    "# 'west2386',\n",
    "# 'wota1240'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function evaluates the model log-likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logprob(phi):\n",
    "    def lprob(sounds):\n",
    "        lp = pm.math.logsumexp(tt.dot(sounds,tt.log(phi.T)))\n",
    "        return(lp)\n",
    "    return(lprob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function runs inference for a batch of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(N_leave_in,Sigma,part_leave_in,sound_count):\n",
    "    model = pm.Model()\n",
    "\n",
    "    with model:\n",
    "        rho = [pm.Uniform('rho_%i'%d,.001,100000) for d in range(D)]            #length scale        \n",
    "        alpha = pm.Uniform('alpha',.001,100000)        #dispersion parameter       \n",
    "        sigma = pm.Uniform('sigma',.001,100000)        #s.d.        \n",
    "        psi = pm.MvNormal('psi',mu=[0]*N_leave_in,\n",
    "                       cov = tt.power(alpha,2)*tt.exp(-.5*tt.sum([tt.power(rho[d],-2)*tt.power(Sigma[d],2)\n",
    "                                               for d in range(D)]))+\n",
    "                      (np.eye(N_leave_in)*tt.power(sigma,2)),\n",
    "                     shape=N_leave_in)             #weights       \n",
    "        phi = tt.concatenate([tt.nnet.softmax(psi[part_leave_in[x][0]:part_leave_in[x][1]])[0] for x in range(len(R_leave_in))])        \n",
    "        target = pm.DensityDist('target',logprob(phi),observed=sound_count)        \n",
    "        inference = pm.ADVI()        \n",
    "        inference.fit(2000,obj_optimizer=pm.adam(learning_rate=.01,beta1=.8),\n",
    "                                        callbacks=[pm.callbacks.CheckParametersConvergence()])\n",
    "        trace = inference.approx.sample()\n",
    "    return(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function uses a posterior sample to predict sound changes for held out data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive(trace,Sigma_full,N_hold_out,N_leave_in,part_hold_out,R_hold_out,sound_count_held_out):\n",
    "    j = np.random.randint(500)\n",
    "\n",
    "    a = trace['psi'][j]\n",
    "    rho = [trace['rho_'+str(d)][j] for d in range(D)]\n",
    "    sigma = trace['sigma'][j]\n",
    "    alpha = trace['alpha'][j]\n",
    "    \n",
    "    Sigma_f = (tt.power(alpha,2)*tt.exp(-.5*tt.sum([tt.power(rho[d],-2)*tt.power(Sigma_full[d],2)\n",
    "                                               for d in range(D)]))+\n",
    "                      (np.eye(N_leave_in+N_hold_out)*tt.power(sigma,2))).eval()\n",
    "    \n",
    "    Sigma_11 = Sigma_f[:N_hold_out,:N_hold_out]\n",
    "    Sigma_22 = Sigma_f[N_hold_out:,N_hold_out:]\n",
    "    Sigma_12 = Sigma_f[:N_hold_out,N_hold_out:]\n",
    "    Sigma_21 = Sigma_f[N_hold_out:,:N_hold_out]\n",
    "    \n",
    "    invSigma_22 = np.linalg.inv(Sigma_22)\n",
    "    CDinv = np.dot(Sigma_12,invSigma_22)\n",
    "    \n",
    "    mu_1 = np.matrix(np.zeros(N_hold_out))\n",
    "    mu_2 = np.matrix(np.zeros(N_leave_in))\n",
    "    mu_bar = np.array((mu_1.transpose() + (CDinv*(np.matrix(a)-mu_2).transpose())).flatten())[0]\n",
    "    Sigma_bar = Sigma_11 - np.dot(CDinv,Sigma_21)\n",
    "    \n",
    "    psi_22 = np.random.multivariate_normal(mu_bar,Sigma_bar)\n",
    "    phi_22 = tt.concatenate([tt.nnet.softmax(psi_22[part_hold_out[x][0]:part_hold_out[x][1]])[0] for x in range(len(R_hold_out))]).eval()\n",
    "    \n",
    "    N = [sum(sound_count_held_out[part_hold_out[x][0]:part_hold_out[x][1]]) for x in range(len(R_hold_out))]\n",
    "    \n",
    "    Z = tt.concatenate([np.random.multinomial(N[x],phi_22[part_hold_out[x][0]:part_hold_out[x][1]]) for x in range(len(R_hold_out))]).eval()\n",
    "    \n",
    "    F_score = f1_score(Z,sound_count_held_out,average='micro')\n",
    "    f = open('f_score.txt','a')\n",
    "    print(lang,F_score,file=f)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full inference and evaluation procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "  del sys.path[0]\n",
      "Average Loss = 2,127.4: 100%|██████████| 2000/2000 [02:46<00:00, 12.02it/s]\n",
      "Finished [100%]: Average Loss = 2,124.6\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "  del sys.path[0]\n",
      "Average Loss = 5,645.1: 100%|██████████| 2000/2000 [05:38<00:00,  5.90it/s]\n",
      "Finished [100%]: Average Loss = 5,640.9\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "  del sys.path[0]\n",
      "Average Loss = 4,604.3: 100%|██████████| 2000/2000 [04:03<00:00,  8.21it/s]\n",
      "Finished [100%]: Average Loss = 4,602.2\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "  del sys.path[0]\n",
      "Average Loss = 11,120: 100%|██████████| 2000/2000 [05:05<00:00,  6.54it/s]\n",
      "Finished [100%]: Average Loss = 11,116\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "  del sys.path[0]\n",
      "Average Loss = 3,170.6: 100%|██████████| 2000/2000 [04:03<00:00,  8.21it/s]\n",
      "Finished [100%]: Average Loss = 3,168.5\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "  del sys.path[0]\n",
      "Average Loss = 10,028:   3%|▎         | 62/2000 [00:09<05:09,  6.27it/s]\n",
      "Interrupted at 62 [3%]: Average Loss = 10,011\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "  del sys.path[0]\n",
      "Average Loss = 1,811.4: 100%|██████████| 2000/2000 [03:50<00:00,  8.67it/s]\n",
      "Finished [100%]: Average Loss = 1,808.8\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "  del sys.path[0]\n",
      "Average Loss = 12,245:  38%|███▊      | 768/2000 [01:39<02:39,  7.71it/s]\n",
      "Interrupted at 768 [38%]: Average Loss = 8,513.7\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-41ba953fff81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msound_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msound_count_held_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSigma_full\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_leave_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_hold_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpart_leave_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpart_hold_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR_leave_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR_hold_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_leave_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpart_leave_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msound_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpredictive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSigma_full\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_hold_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_leave_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpart_hold_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR_hold_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msound_count_held_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-95b289e59480>\u001b[0m in \u001b[0;36mpredictive\u001b[0;34m(trace, Sigma_full, N_hold_out, N_leave_in, part_hold_out, R_hold_out, sound_count_held_out)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mpsi_22\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSigma_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mphi_22\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsi_22\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpart_hold_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpart_hold_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_hold_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msound_count_held_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpart_hold_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpart_hold_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_hold_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-95b289e59480>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mpsi_22\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSigma_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mphi_22\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsi_22\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpart_hold_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpart_hold_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_hold_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msound_count_held_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpart_hold_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpart_hold_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_hold_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/tensor/nnet/nnet.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcastable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The softmax is applied on a dimension of shape 1, which does not have a semantic meaning.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msoftmax_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \"\"\"\n\u001b[1;32m    614\u001b[0m         \u001b[0mreturn_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'return_list'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_test_value\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'off'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/tensor/nnet/nnet.py\u001b[0m in \u001b[0;36mmake_node\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    434\u001b[0m                           \u001b[0;34m\"vector case is gonna be supported soon and the output will be a vector.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                           stacklevel=4)\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_padleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_ones\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/tensor/basic.py\u001b[0m in \u001b[0;36mshape_padleft\u001b[0;34m(t, n_ones)\u001b[0m\n\u001b[1;32m   4551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4552\u001b[0m     \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_ones\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4553\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDimShuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcastable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;31m# compute output value once with test inputs to validate graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 thunk = node.op.make_thunk(node, storage_map, compute_map,\n\u001b[0;32m--> 670\u001b[0;31m                                            no_recycling=[])\n\u001b[0m\u001b[1;32m    671\u001b[0m                 \u001b[0mthunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0mthunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, node, storage_map, compute_map, no_recycling, impl)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m                 return self.make_c_thunk(node, storage_map, compute_map,\n\u001b[0;32m--> 955\u001b[0;31m                                          no_recycling)\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethodNotDefined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m                 \u001b[0;31m# We requested the c code, so don't catch the error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mmake_c_thunk\u001b[0;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trying CLinker.make_thunk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         outputs = cl.make_thunk(input_storage=node_input_storage,\n\u001b[0;32m--> 858\u001b[0;31m                                 output_storage=node_output_storage)\n\u001b[0m\u001b[1;32m    859\u001b[0m         \u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_input_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_output_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1215\u001b[0m         cthunk, module, in_storage, out_storage, error_storage = self.__compile__(\n\u001b[1;32m   1216\u001b[0m             \u001b[0minput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CThunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcthunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36m__compile__\u001b[0;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1155\u001b[0m                                             \u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                                             \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m                                             keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1158\u001b[0m         return (thunk,\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mcthunk_factory\u001b[0;34m(self, error_storage, in_storage, out_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1618\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m             module = get_module_cache().module_from_key(\n\u001b[0;32m-> 1620\u001b[0;31m                 key=key, lnk=self, keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m         \u001b[0mvars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morphans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/gof/cmodule.py\u001b[0m in \u001b[0;36mmodule_from_key\u001b[0;34m(self, key, lnk, keep_lock)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;31m# Is the source code already in the cache?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0mmodule_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_module_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_from_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_hash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_lock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/gof/cmodule.py\u001b[0m in \u001b[0;36m_get_from_hash\u001b[0;34m(self, module_hash, key, keep_lock)\u001b[0m\n\u001b[1;32m   1048\u001b[0m                 if (key[0] and not key_broken and\n\u001b[1;32m   1049\u001b[0m                         self.check_for_broken_eq):\n\u001b[0;32m-> 1050\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_mappings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_in_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mkey_broken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/gof/cmodule.py\u001b[0m in \u001b[0;36mcheck_key\u001b[0;34m(self, key, key_pkl)\u001b[0m\n\u001b[1;32m   1252\u001b[0m         \u001b[0;31m# part of the key is not broken.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mother\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilar_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_safe_part\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m                 raise AssertionError(\n\u001b[1;32m   1256\u001b[0m                     \u001b[0;34m\"Found two keys that are equal but have a different hash. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/tensor/type.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \"\"\"\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcastable\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcastable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for t in range(100):\n",
    "    for lang in langs:\n",
    "        sound_count,sound_count_held_out,Sigma,Sigma_full,N_leave_in,N_hold_out,part_leave_in,part_hold_out,R_leave_in,R_hold_out = gen_batch(lang)\n",
    "        trace=run_model(N_leave_in,Sigma,part_leave_in,sound_count)\n",
    "        predictive(trace,Sigma_full,N_hold_out,N_leave_in,part_hold_out,R_hold_out,sound_count_held_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
